{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tf  {border-collapse:collapse;border-spacing:0;width:100%}\n",
    ".tf td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tf th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tf .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    ".col1 { width: 20%;}\n",
    ".col2 { width: 80%;}\n",
    "</style>\n",
    "<table class=\"tf\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky col1\">Name</th>\n",
    "    <th class=\"tg-0pky col2\">Hatim Sawai</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky col1\">UID No.</td>\n",
    "    <td class=\"tg-0pky col2\">2021300108</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky col1\">Experiment No.</td>\n",
    "    <td class=\"tg-0pky col2\">3</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align:center;font-weight:500;\">Experiment 3</p>\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;width:100%}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 10px;word-break:normal;}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top;}\n",
    ".col1 { width: 20%;}\n",
    ".col2 { width: 80%;}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky col1\">Aim</th>\n",
    "    <th class=\"tg-0pky col2\">1. Calculate bigrams from a given corpus , display bigram probability table and calculate probability of a sentence.\n",
    "    <br>2. To apply add-one smoothing on sparse bigram table</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Installation of NLTK and downloading the required corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import wordnet\n",
    "from prettytable import PrettyTable\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pattern.text.en import pluralize, conjugate, comparative\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shabb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\shabb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shabb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Preprocessing of the given corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data from input.txt\n",
    "with open(\"input.txt\", \"r\") as file:\n",
    "    data = file.read()\n",
    "\n",
    "data = data.lower()\n",
    "data = data.replace(\",\", \"\").replace(\".\", \" eos\").replace(\"!\", \" eos\").replace(\"?\", \" eos\").replace(\":\", \"\").replace(\";\", \"\").replace(\"'\", \"\").replace('\"', \"\")\n",
    "data = data.replace(\"'s\", \"\")\n",
    "data = \"eos \" + data\n",
    "tokens = word_tokenize(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eos', 'you', 'book', 'a', 'flight', 'eos', 'i', 'read', 'a', 'book', 'eos', 'you', 'read', 'eos']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Calculating bigrams from the given corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+-----+------+-----+--------+------+------+\n",
      "|        | eos | you | book |  a  | flight |  i   | read |\n",
      "+--------+-----+-----+------+-----+--------+------+------+\n",
      "|  eos   | 0.0 | 0.5 | 0.0  | 0.0 |  0.0   | 0.25 | 0.0  |\n",
      "|  you   | 0.0 | 0.0 | 0.5  | 0.0 |  0.0   | 0.0  | 0.5  |\n",
      "|  book  | 0.5 | 0.0 | 0.0  | 0.5 |  0.0   | 0.0  | 0.0  |\n",
      "|   a    | 0.0 | 0.0 | 0.5  | 0.0 |  0.5   | 0.0  | 0.0  |\n",
      "| flight | 1.0 | 0.0 | 0.0  | 0.0 |  0.0   | 0.0  | 0.0  |\n",
      "|   i    | 0.0 | 0.0 | 0.0  | 0.0 |  0.0   | 0.0  | 1.0  |\n",
      "|  read  | 0.5 | 0.0 | 0.0  | 0.5 |  0.0   | 0.0  | 0.0  |\n",
      "+--------+-----+-----+------+-----+--------+------+------+\n"
     ]
    }
   ],
   "source": [
    "# create bigram table using pretty table\n",
    "unique = [\"\"] + tokens\n",
    "h = {}\n",
    "for i in unique:\n",
    "    h[i] = tokens.count(i)\n",
    "unique = pd.unique(unique)\n",
    "bigram_table = PrettyTable()\n",
    "bigram_table.field_names = [i for i in unique]\n",
    "unique = unique[1:]\n",
    "for i in unique:\n",
    "    row = [i]\n",
    "    for j in unique:\n",
    "        count = 0\n",
    "        for k in range(len(tokens) - 1):\n",
    "            if tokens[k] == i and tokens[k + 1] == j:\n",
    "                count += 1\n",
    "        p = count/h[i]\n",
    "        row.append(p)\n",
    "    bigram_table.add_row(row)\n",
    "\n",
    "print(bigram_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+------+------+--------+------+------+\n",
      "|        | eos  | you  | book |  a   | flight |  i   | read |\n",
      "+--------+------+------+------+------+--------+------+------+\n",
      "|  eos   | 0.09 | 0.27 | 0.09 | 0.09 |  0.09  | 0.18 | 0.09 |\n",
      "|  you   | 0.11 | 0.11 | 0.22 | 0.11 |  0.11  | 0.11 | 0.22 |\n",
      "|  book  | 0.22 | 0.11 | 0.11 | 0.22 |  0.11  | 0.11 | 0.11 |\n",
      "|   a    | 0.11 | 0.11 | 0.22 | 0.11 |  0.22  | 0.11 | 0.11 |\n",
      "| flight | 0.25 | 0.12 | 0.12 | 0.12 |  0.12  | 0.12 | 0.12 |\n",
      "|   i    | 0.12 | 0.12 | 0.12 | 0.12 |  0.12  | 0.12 | 0.25 |\n",
      "|  read  | 0.22 | 0.11 | 0.11 | 0.22 |  0.11  | 0.11 | 0.11 |\n",
      "|  eos   | 0.09 | 0.27 | 0.09 | 0.09 |  0.09  | 0.18 | 0.09 |\n",
      "|  you   | 0.11 | 0.11 | 0.22 | 0.11 |  0.11  | 0.11 | 0.22 |\n",
      "|  book  | 0.22 | 0.11 | 0.11 | 0.22 |  0.11  | 0.11 | 0.11 |\n",
      "|   a    | 0.11 | 0.11 | 0.22 | 0.11 |  0.22  | 0.11 | 0.11 |\n",
      "| flight | 0.25 | 0.12 | 0.12 | 0.12 |  0.12  | 0.12 | 0.12 |\n",
      "|   i    | 0.12 | 0.12 | 0.12 | 0.12 |  0.12  | 0.12 | 0.25 |\n",
      "|  read  | 0.22 | 0.11 | 0.11 | 0.22 |  0.11  | 0.11 | 0.11 |\n",
      "+--------+------+------+------+------+--------+------+------+\n"
     ]
    }
   ],
   "source": [
    "# create add one smoothing bigram table using pretty table\n",
    "unique = [\"\"] + tokens\n",
    "unique = pd.unique(unique)\n",
    "smooth_table = PrettyTable()\n",
    "smooth_table.field_names = [i for i in unique]\n",
    "unique = unique[1:]\n",
    "for i in unique:\n",
    "    row = [i]\n",
    "    for j in unique:\n",
    "        count = 0\n",
    "        for k in range(len(tokens) - 1):\n",
    "            if tokens[k] == i and tokens[k + 1] == j:\n",
    "                count += 1\n",
    "        p = (count+1)/(h[i]+len(unique))\n",
    "        p = round(p, 2)\n",
    "        row.append(p)\n",
    "    bigram_table.add_row(row)\n",
    "\n",
    "print(bigram_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Curiosity Questions\n",
    "<p style=\"font-weight:500;\">Q1. What is paradigm class? Give example.</p>\n",
    "Ans: In linguistics, a paradigm class refers to a set of words or forms that share a similar grammatical pattern or inflectional morphology. It involves grouping words based on their shared grammatical features, such as tense, number, gender, or case. Paradigm classes help linguists analyze and understand the systematic relationships between different forms of words within a language.  \n",
    "\n",
    "Example:  \n",
    "Consider the English verb \"to be\" in the present tense for different pronouns:  \n",
    "\n",
    "I am  \n",
    "You are  \n",
    "We are  \n",
    "He/She/It is\n",
    "\n",
    "In this case, the paradigm class is formed by the variations of the verb \"to be\" based on different pronouns, and they share the same grammatical pattern within the present tense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:500;\">Q2. What are the different types of morphemes. Give example of each.</p>\n",
    "Ans: Morphemes are the smallest units of meaning in a language. There are two main types of morphemes: free morphemes and bound morphemes.  \n",
    "\n",
    "<p style=\"font-weight:500;\">a. Free Morpheme:</p> \n",
    "A free morpheme is a morpheme that can stand alone as a word and carry meaning by itself.\n",
    "\n",
    "Example:  \n",
    "\"Dog\" - In this case, \"dog\" is a free morpheme as it can stand alone and has a distinct meaning.  \n",
    "\n",
    "<p style=\"font-weight:500;\">b. Bound Morpheme:</p>\n",
    "A bound morpheme is a morpheme that cannot stand alone as a word and needs to be attached to a free morpheme to convey meaning.  \n",
    "\n",
    "Example:  \n",
    "\"Un-\" (prefix meaning \"not\") - In the word \"unhappy,\" \"un-\" is a bound morpheme because it cannot stand alone and needs to be attached to \"happy\" to convey the meaning of \"not happy.\"  \n",
    "\n",
    "<p style=\"font-weight:500;\">c. Inflectional Morpheme:</p>\n",
    "An inflectional morpheme is a type of bound morpheme that indicates grammatical information, such as tense, number, or gender.  \n",
    "\n",
    "Example:  \n",
    "\"-s\" (plural marker) in \"cats\" - The morpheme \"-s\" is inflectional as it changes the number of the noun \"cat\" from singular to plural.  \n",
    "\n",
    "<p style=\"font-weight:500;\">d. Derivational Morpheme:</p> \n",
    "A derivational morpheme is a type of bound morpheme that creates a new word or changes the meaning or grammatical category of a word.  \n",
    "\n",
    "Example:  \n",
    "\"-er\" (suffix forming agent nouns) in \"teacher\" - The morpheme \"-er\" is derivational as it changes the base word \"teach\" into a new word with a different grammatical category and meaning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusion\n",
    "In this experiment we learned about the different types of morphemes and how to generate word forms from root and suffix information using Add-Delete table. We also learned about the comparative study of Porter/Snowball/Lancaster Stemmer and Stemmer vs Lemmatizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
