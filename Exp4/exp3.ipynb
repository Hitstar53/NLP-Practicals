{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tf  {border-collapse:collapse;border-spacing:0;width:100%}\n",
    ".tf td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tf th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tf .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    ".col1 { width: 20%;}\n",
    ".col2 { width: 80%;}\n",
    "</style>\n",
    "<table class=\"tf\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky col1\">Name</th>\n",
    "    <th class=\"tg-0pky col2\">Hatim Sawai</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky col1\">UID No.</td>\n",
    "    <td class=\"tg-0pky col2\">2021300108</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky col1\">Experiment No.</td>\n",
    "    <td class=\"tg-0pky col2\">4</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align:center;font-weight:500;\">Experiment 4</p>\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;width:100%}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 10px;word-break:normal;}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top;}\n",
    ".col1 { width: 20%;}\n",
    ".col2 { width: 80%;}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky col1\">Aim</th>\n",
    "    <th class=\"tg-0pky col2\">Classification using suitable classification model (NB).\n",
    "    </th>\n",
    "  </tr>\n",
    "</thead>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Installation of NLTK and downloading the required corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import wordnet\n",
    "from prettytable import PrettyTable\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pattern.text.en import pluralize, conjugate, comparative\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shabb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\shabb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shabb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Load Dataset & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv dataset\n",
    "def load_dataset(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    documents = df['Text'].tolist()\n",
    "    labels = df['Label'].tolist()\n",
    "    return documents, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # remove punctuation\n",
    "    text = text.replace(\"\\n\", \" \") # remove \\n\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespaces\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build vocabulary\n",
    "def build_vocabulary(documents):\n",
    "    vocabulary = set()\n",
    "    for document in documents:\n",
    "        words = document.split()\n",
    "        vocabulary.update(words)\n",
    "    return list(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_occurrences(document, vocabulary):\n",
    "    word_counts = {word: 0 for word in vocabulary}\n",
    "    words = document.split()\n",
    "    for word in words:\n",
    "        if word in word_counts:\n",
    "            word_counts[word] += 1\n",
    "    return word_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Making the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_naive_bayes(documents, labels):\n",
    "    unique_labels = set(labels)\n",
    "    label_probs = {label: labels.count(label) / len(labels) for label in unique_labels}\n",
    "    \n",
    "    vocabulary = build_vocabulary(documents)\n",
    "    \n",
    "    word_probs = {label: {word: 0 for word in vocabulary} for label in unique_labels}\n",
    "    \n",
    "    for i, document in enumerate(documents):\n",
    "        label = labels[i]\n",
    "        word_counts = count_word_occurrences(document, vocabulary)\n",
    "        for word, count in word_counts.items():\n",
    "            word_probs[label][word] += count\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        total_count = sum(word_probs[label].values())\n",
    "        for word, count in word_probs[label].items():\n",
    "            word_probs[label][word] = (count + 1) / (total_count + len(vocabulary))\n",
    "    \n",
    "    return label_probs, word_probs, vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_naive_bayes(document, label_probs, word_probs, vocabulary):\n",
    "    document = preprocess(document)\n",
    "    word_counts = count_word_occurrences(document, vocabulary)\n",
    "    scores = {label: np.log(label_probs[label]) for label in label_probs}\n",
    "    for label in label_probs:\n",
    "        for word, count in word_counts.items():\n",
    "            if word in vocabulary:\n",
    "                scores[label] += count * np.log(word_probs[label][word])\n",
    "    return max(scores, key=scores.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classifier(test_documents, test_labels, label_probs, word_probs, vocabulary):\n",
    "    true_positive, false_positive, true_negative, false_negative = 0, 0, 0, 0\n",
    "    print(\"Evaluating the classifier...\")\n",
    "    for i, document in enumerate(test_documents):\n",
    "        predicted_label = classify_naive_bayes(document, label_probs, word_probs, vocabulary)\n",
    "        true_label = test_labels[i]\n",
    "        \n",
    "        if predicted_label == true_label:\n",
    "            if predicted_label == 1:  # Sports\n",
    "                true_positive += 1\n",
    "            else:\n",
    "                true_negative += 1\n",
    "        else:\n",
    "            if predicted_label == 1:  # Sports\n",
    "                false_positive += 1\n",
    "            else:\n",
    "                false_negative += 1\n",
    "        print(f\"Document {i+1} - True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
    "    \n",
    "    accuracy = (true_positive + true_negative) / len(test_documents)\n",
    "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    confusion_matrix = np.array([[true_positive, false_positive], [false_negative, true_negative]])\n",
    "    \n",
    "    return accuracy, precision, recall, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2225 documents\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from CSV\n",
    "csv_path = \"./Dataset/df_file.csv\"\n",
    "documents, labels = load_dataset(csv_path)\n",
    "print(f\"Loaded {len(documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 1780 documents\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets (80% training, 20% testing) using sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_documents, test_documents, train_labels, test_labels = train_test_split(documents, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set: {len(train_documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the Naive Bayes classifier\n",
    "label_probs, word_probs, vocabulary = train_naive_bayes(train_documents, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating the classifier...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate the classifier\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m accuracy, precision, recall, f1_score, confusion_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_classifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[63], line 5\u001b[0m, in \u001b[0;36mevaluate_classifier\u001b[1;34m(test_documents, test_labels, label_probs, word_probs, vocabulary)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating the classifier...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, document \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(test_documents):\n\u001b[1;32m----> 5\u001b[0m     predicted_label \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_naive_bayes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdocument\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mword_probs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocabulary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     true_label \u001b[38;5;241m=\u001b[39m test_labels[i]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m predicted_label \u001b[38;5;241m==\u001b[39m true_label:\n",
      "Cell \u001b[1;32mIn[51], line 10\u001b[0m, in \u001b[0;36mclassify_naive_bayes\u001b[1;34m(document, label_probs, word_probs, vocabulary)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m word, count \u001b[38;5;129;01min\u001b[39;00m word_counts\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m vocabulary:\n\u001b[1;32m---> 10\u001b[0m             scores[label] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m count \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(word_probs[label][word])\n\u001b[0;32m     12\u001b[0m predicted_label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(scores, key\u001b[38;5;241m=\u001b[39mscores\u001b[38;5;241m.\u001b[39mget)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predicted_label\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Evaluate the classifier\n",
    "accuracy, precision, recall, f1_score, confusion_matrix = evaluate_classifier(test_documents, test_labels, label_probs, word_probs, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1_score)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"page-break-after:always;\"></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Curiosity Questions\n",
    "<p style=\"font-weight:500;\">Q1. Some Terminologies</p>  \n",
    " \n",
    "1. **Corpus**: A corpus is a collection of written texts and is used for language research and development.  \n",
    "2. **Bigram**: A bigram is a sequence of two adjacent elements from a string of tokens, which are typically letters, syllables, or words. A bigram is an n-gram for n=2.  \n",
    "3. **Add-one Smoothing**: Add-one smoothing is a simple method to smooth zero probabilities in a probability distribution. It is also known as Laplace smoothing.  \n",
    "4. **Sparse Table**: A sparse table is a table that has a large number of cells with zero values. It is a table in which most of the entries are zero.  \n",
    "5. **Word Form:** the inflected form as it actually appears in the corpus.  \n",
    "6. **Lemma:** an abstract form, shared by word forms having the same stem, part of speech, and word sense – stands for the class of words with stem.  \n",
    "7. **Types:** number of distinct words in a corpus (vocabulary size).  \n",
    "8. **Tokens:** total number of words in a corpus.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:500;\">Q2. What is Bi-gram Model? How to calculate the probability of a sentence?</p>\n",
    "Ans: A bigram model is a type of n-gram language model where \"n\" equals 2. In simpler terms, it predicts the next word in a sentence based solely on the word that came before it. This assumption, termed the Markov assumption, states that the probability of a word depends only on the previous word, ignoring all preceding context. While simplistic, bigram models hold historical significance as the foundation for more complex language models.  \n",
    "\n",
    "**Calculating Sentence Probability:**  \n",
    "Here's how to calculate the probability of a sentence in a bigram model:  \n",
    "1. Tokenize the sentence: Divide the sentence into individual words (tokens).\n",
    "2. Estimate bigram probabilities: Calculate the probability of each word following the previous word in the training corpus. This uses the formula: **P(w_i | w_(i-1)) = Count(w_(i-1), w_i) / Count(w_(i-1))**    \n",
    "\n",
    "where:  \n",
    "P(w_i | w_(i-1)) is the probability of word w_i given the previous word w_(i-1).  \n",
    "Count(w_(i-1), w_i) is the number of times the bigram (w_(i-1), w_i) appears in the training corpus.  \n",
    "Count(w_(i-1)) is the number of times the word w_(i-1) appears in the training corpus.  \n",
    "Multiply probabilities: Multiply the individual bigram probabilities for each word pair in the sentence.  \n",
    "\n",
    "3. Smoothing: Since most word pairs might not be present in the corpus, apply smoothing techniques like Laplace smoothing or Witten-Bell discounting to adjust probabilities and avoid zero probabilities.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusion\n",
    "In this experiment we learned about bigrams and add-one smoothing. We calculated bigrams from a given corpus and displayed the bigram probability table. We also calculated the probability of a sentence using bigram probabilities. We also applied add-one smoothing on the sparse bigram table."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
