{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tf  {border-collapse:collapse;border-spacing:0;width:100%}\n",
    ".tf td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tf th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tf .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    ".col1 { width: 20%;}\n",
    ".col2 { width: 80%;}\n",
    "</style>\n",
    "<table class=\"tf\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky col1\">Name</th>\n",
    "    <th class=\"tg-0pky col2\">Hatim Sawai</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky col1\">UID No.</td>\n",
    "    <td class=\"tg-0pky col2\">2021300108</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky col1\">Experiment No.</td>\n",
    "    <td class=\"tg-0pky col2\">2</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align:center;font-weight:500;\">Experiment 2</p>\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;width:100%}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 10px;word-break:normal;}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top;}\n",
    ".col1 { width: 20%;}\n",
    ".col2 { width: 80%;}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky col1\">Aim</th>\n",
    "    <th class=\"tg-0pky col2\">1. Generate word forms from root and suffix information using Add-Delete table.\n",
    "<br>2. Comparative study of Porter/Snowball/Lancaster Stemmer and Stemmer vs Lemmatizer</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Installation of NLTK and downloading the required corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatim\\AppData\\Local\\Temp\\ipykernel_20776\\1792132151.py:2: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import wordnet\n",
    "from prettytable import PrettyTable\n",
    "from nltk.tokenize import word_tokenize\n",
    "from pattern.text.en import pluralize, conjugate, comparative\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer, LancasterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generating word forms from root using Add-Delete table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"run\", \"jump\", \"play\", \"sleep\", \"eat\", \"walk\", \"read\", \"write\", \"sing\", \"think\", \"cry\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate diiferent forms of words\n",
    "def generate_wordforms(words):\n",
    "    wordforms = []\n",
    "    for word in words:\n",
    "        forms = []\n",
    "        forms.append(word)\n",
    "        forms.append(pluralize(word))\n",
    "        forms.append(comparative(word))\n",
    "        forms.append(conjugate(word, tense=\"past\"))\n",
    "        forms.append(conjugate(word, tense=\"part\"))\n",
    "        wordforms.append(forms)\n",
    "    return wordforms\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add and delete table for each word form\n",
    "def calc_add_del(wordform_arr):\n",
    "    root = wordform_arr[0]\n",
    "    table = PrettyTable()\n",
    "    table.field_names = [\"Root\", \"Del\", \"Add\", \"Chars\", \"Word Form\"]\n",
    "    table.align[\"Chars\"] = \"l\"\n",
    "    table.align[\"Word Form\"] = \"l\"\n",
    "    for i,form in enumerate(wordform_arr):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            # count equal chars break at first unequal\n",
    "            for j,char in enumerate(root):\n",
    "                if char != form[j]:\n",
    "                    break\n",
    "            if len(root) != len(form):\n",
    "                j += 1\n",
    "            # count chars after first unequal\n",
    "            add = len(form[j:])\n",
    "            delete = len(root[j:])\n",
    "            wordform_arr[i] = [delete, add, form[j:], form]\n",
    "            table.add_row([root, delete, add, form[j:], form])\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+-----+-------+-----------+\n",
      "| Root | Del | Add | Chars | Word Form |\n",
      "+------+-----+-----+-------+-----------+\n",
      "| run  |  0  |  1  | s     | runs      |\n",
      "| run  |  0  |  3  | ner   | runner    |\n",
      "| run  |  2  |  2  | an    | ran       |\n",
      "| run  |  0  |  4  | ning  | running   |\n",
      "+------+-----+-----+-------+-----------+\n",
      "+------+-----+-----+-------+-----------+\n",
      "| Root | Del | Add | Chars | Word Form |\n",
      "+------+-----+-----+-------+-----------+\n",
      "| jump |  0  |  1  | s     | jumps     |\n",
      "| jump |  0  |  2  | er    | jumper    |\n",
      "| jump |  0  |  2  | ed    | jumped    |\n",
      "| jump |  0  |  3  | ing   | jumping   |\n",
      "+------+-----+-----+-------+-----------+\n",
      "+------+-----+-----+-------+-----------+\n",
      "| Root | Del | Add | Chars | Word Form |\n",
      "+------+-----+-----+-------+-----------+\n",
      "| play |  0  |  1  | s     | plays     |\n",
      "| play |  0  |  2  | er    | player    |\n",
      "| play |  0  |  2  | ed    | played    |\n",
      "| play |  0  |  3  | ing   | playing   |\n",
      "+------+-----+-----+-------+-----------+\n",
      "+-------+-----+-----+-------+-----------+\n",
      "|  Root | Del | Add | Chars | Word Form |\n",
      "+-------+-----+-----+-------+-----------+\n",
      "| sleep |  0  |  1  | s     | sleeps    |\n",
      "| sleep |  0  |  2  | er    | sleeper   |\n",
      "| sleep |  2  |  2  | pt    | slept     |\n",
      "| sleep |  0  |  3  | ing   | sleeping  |\n",
      "+-------+-----+-----+-------+-----------+\n",
      "+------+-----+-----+-------+-----------+\n",
      "| Root | Del | Add | Chars | Word Form |\n",
      "+------+-----+-----+-------+-----------+\n",
      "| eat  |  0  |  1  | s     | eats      |\n",
      "| eat  |  0  |  2  | er    | eater     |\n",
      "| eat  |  3  |  3  | ate   | ate       |\n",
      "| eat  |  0  |  3  | ing   | eating    |\n",
      "+------+-----+-----+-------+-----------+\n",
      "+------+-----+-----+-------+-----------+\n",
      "| Root | Del | Add | Chars | Word Form |\n",
      "+------+-----+-----+-------+-----------+\n",
      "| walk |  0  |  1  | s     | walks     |\n",
      "| walk |  0  |  2  | er    | walker    |\n",
      "| walk |  0  |  2  | ed    | walked    |\n",
      "| walk |  0  |  3  | ing   | walking   |\n",
      "+------+-----+-----+-------+-----------+\n",
      "+------+-----+-----+-------+-----------+\n",
      "| Root | Del | Add | Chars | Word Form |\n",
      "+------+-----+-----+-------+-----------+\n",
      "| read |  0  |  1  | s     | reads     |\n",
      "| read |  0  |  2  | er    | reader    |\n",
      "| read |  1  |  1  | d     | read      |\n",
      "| read |  0  |  3  | ing   | reading   |\n",
      "+------+-----+-----+-------+-----------+\n",
      "+-------+-----+-----+-------+-----------+\n",
      "|  Root | Del | Add | Chars | Word Form |\n",
      "+-------+-----+-----+-------+-----------+\n",
      "| write |  0  |  1  | s     | writes    |\n",
      "| write |  0  |  1  | r     | writer    |\n",
      "| write |  3  |  3  | ote   | wrote     |\n",
      "| write |  0  |  2  | ng    | writing   |\n",
      "+-------+-----+-----+-------+-----------+\n",
      "+------+-----+-----+-------+-----------+\n",
      "| Root | Del | Add | Chars | Word Form |\n",
      "+------+-----+-----+-------+-----------+\n",
      "| sing |  0  |  1  | s     | sings     |\n",
      "| sing |  0  |  2  | er    | singer    |\n",
      "| sing |  3  |  3  | ung   | sung      |\n",
      "| sing |  0  |  3  | ing   | singing   |\n",
      "+------+-----+-----+-------+-----------+\n",
      "+-------+-----+-----+-------+-----------+\n",
      "|  Root | Del | Add | Chars | Word Form |\n",
      "+-------+-----+-----+-------+-----------+\n",
      "| think |  0  |  1  | s     | thinks    |\n",
      "| think |  0  |  2  | er    | thinker   |\n",
      "| think |  2  |  4  | ught  | thought   |\n",
      "| think |  0  |  3  | ing   | thinking  |\n",
      "+-------+-----+-----+-------+-----------+\n",
      "+------+-----+-----+-------+-----------+\n",
      "| Root | Del | Add | Chars | Word Form |\n",
      "+------+-----+-----+-------+-----------+\n",
      "| cry  |  0  |  2  | es    | cries     |\n",
      "| cry  |  0  |  2  | er    | cryer     |\n",
      "| cry  |  0  |  2  | ed    | cried     |\n",
      "| cry  |  0  |  3  | ing   | crying    |\n",
      "+------+-----+-----+-------+-----------+\n"
     ]
    }
   ],
   "source": [
    "wordforms = generate_wordforms(words)\n",
    "\n",
    "for i, wordform in enumerate(wordforms):\n",
    "    calc_add_del(wordforms[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Comparative study of Porter/Snowball/Lancaster Stemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read setences from input.txt\n",
    "with open(\"input.txt\") as f:\n",
    "    sentences = f.readlines()\n",
    "\n",
    "# Tokenize the sentences\n",
    "tokenized_sentences = [word_tokenize(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize stemmers and lemmatizer\n",
    "porter_stemmer = PorterStemmer()\n",
    "snowball_stemmer = SnowballStemmer(\"english\")\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sentence: The enigmatic detective carefully examined the mysterious crime scene.\n",
      "\n",
      "+------------+---------+----------+-----------+------------+\n",
      "|    Word    |  Porter | Snowball | Lancaster | Lemmatizer |\n",
      "+------------+---------+----------+-----------+------------+\n",
      "|    The     |   the   |   the    |    the    |    The     |\n",
      "| enigmatic  | enigmat | enigmat  |   enigm   | enigmatic  |\n",
      "| detective  |  detect |  detect  |   detect  | detective  |\n",
      "| carefully  |   care  |   care   |    car    | carefully  |\n",
      "|  examined  |  examin |  examin  |   examin  |  examine   |\n",
      "|    the     |   the   |   the    |    the    |    the     |\n",
      "| mysterious | mysteri | mysteri  |  mystery  | mysterious |\n",
      "|   crime    |  crime  |  crime   |    crim   |   crime    |\n",
      "|   scene    |  scene  |  scene   |    scen   |   scene    |\n",
      "|     .      |    .    |    .     |     .     |     .      |\n",
      "+------------+---------+----------+-----------+------------+\n",
      "\n",
      "Sentence: Her effervescent personality lights up the room, bringing joy to everyone around her.\n",
      "\n",
      "+--------------+-----------+-----------+-----------+--------------+\n",
      "|     Word     |   Porter  |  Snowball | Lancaster |  Lemmatizer  |\n",
      "+--------------+-----------+-----------+-----------+--------------+\n",
      "|     Her      |    her    |    her    |    her    |     Her      |\n",
      "| effervescent | effervesc | effervesc | effervesc | effervescent |\n",
      "| personality  |   person  |   person  |   person  | personality  |\n",
      "|    lights    |   light   |   light   |   light   |    light     |\n",
      "|      up      |     up    |     up    |     up    |      up      |\n",
      "|     the      |    the    |    the    |    the    |     the      |\n",
      "|     room     |    room   |    room   |    room   |     room     |\n",
      "|      ,       |     ,     |     ,     |     ,     |      ,       |\n",
      "|   bringing   |   bring   |   bring   |   bring   |    bring     |\n",
      "|     joy      |    joy    |    joy    |    joy    |     joy      |\n",
      "|      to      |     to    |     to    |     to    |      to      |\n",
      "|   everyone   |  everyon  |  everyon  |  everyon  |   everyone   |\n",
      "|    around    |   around  |   around  |   around  |    around    |\n",
      "|     her      |    her    |    her    |    her    |     her      |\n",
      "|      .       |     .     |     .     |     .     |      .       |\n",
      "+--------------+-----------+-----------+-----------+--------------+\n",
      "\n",
      "Sentence: A cacophony of sounds filled the bustling market as people went about their daily activities.\n",
      "\n",
      "+------------+-----------+-----------+-----------+------------+\n",
      "|    Word    |   Porter  |  Snowball | Lancaster | Lemmatizer |\n",
      "+------------+-----------+-----------+-----------+------------+\n",
      "|     A      |     a     |     a     |     a     |     A      |\n",
      "| cacophony  | cacophoni | cacophoni | cacophony | cacophony  |\n",
      "|     of     |     of    |     of    |     of    |     of     |\n",
      "|   sounds   |   sound   |   sound   |   sound   |   sound    |\n",
      "|   filled   |    fill   |    fill   |    fil    |    fill    |\n",
      "|    the     |    the    |    the    |    the    |    the     |\n",
      "|  bustling  |   bustl   |   bustl   |   bustl   |   bustle   |\n",
      "|   market   |   market  |   market  |   market  |   market   |\n",
      "|     as     |     as    |     as    |     as    |     as     |\n",
      "|   people   |   peopl   |   peopl   |   peopl   |   people   |\n",
      "|    went    |    went   |    went   |    went   |     go     |\n",
      "|   about    |   about   |   about   |   about   |   about    |\n",
      "|   their    |   their   |   their   |   their   |   their    |\n",
      "|   daily    |   daili   |   daili   |    dai    |   daily    |\n",
      "| activities |   activ   |   activ   |    act    | activities |\n",
      "|     .      |     .     |     .     |     .     |     .      |\n",
      "+------------+-----------+-----------+-----------+------------+\n",
      "\n",
      "Sentence: The resilient athlete overcame numerous obstacles to achieve victory in the championship.\n",
      "\n",
      "+--------------+--------------+--------------+-----------+--------------+\n",
      "|     Word     |    Porter    |   Snowball   | Lancaster |  Lemmatizer  |\n",
      "+--------------+--------------+--------------+-----------+--------------+\n",
      "|     The      |     the      |     the      |    the    |     The      |\n",
      "|  resilient   |    resili    |    resili    |    resy   |  resilient   |\n",
      "|   athlete    |    athlet    |    athlet    |   athlet  |   athlete    |\n",
      "|   overcame   |   overcam    |   overcam    |  overcam  |   overcome   |\n",
      "|   numerous   |    numer     |    numer     |    num    |   numerous   |\n",
      "|  obstacles   |   obstacl    |   obstacl    |   obstac  |  obstacles   |\n",
      "|      to      |      to      |      to      |     to    |      to      |\n",
      "|   achieve    |    achiev    |    achiev    |   achiev  |   achieve    |\n",
      "|   victory    |   victori    |   victori    |    vict   |   victory    |\n",
      "|      in      |      in      |      in      |     in    |      in      |\n",
      "|     the      |     the      |     the      |    the    |     the      |\n",
      "| championship | championship | championship |   champ   | championship |\n",
      "|      .       |      .       |      .       |     .     |      .       |\n",
      "+--------------+--------------+--------------+-----------+--------------+\n",
      "\n",
      "Sentence: The intricate details of the antique clock fascinated collectors and historians alike.\n",
      "\n",
      "+------------+-----------+-----------+-----------+------------+\n",
      "|    Word    |   Porter  |  Snowball | Lancaster | Lemmatizer |\n",
      "+------------+-----------+-----------+-----------+------------+\n",
      "|    The     |    the    |    the    |    the    |    The     |\n",
      "| intricate  |   intric  |   intric  |    int    | intricate  |\n",
      "|  details   |   detail  |   detail  |   detail  |   detail   |\n",
      "|     of     |     of    |     of    |     of    |     of     |\n",
      "|    the     |    the    |    the    |    the    |    the     |\n",
      "|  antique   |   antiqu  |   antiqu  |    ant    |  antique   |\n",
      "|   clock    |   clock   |   clock   |   clock   |   clock    |\n",
      "| fascinated |   fascin  |   fascin  |   fascin  | fascinate  |\n",
      "| collectors | collector | collector |  collect  | collectors |\n",
      "|    and     |    and    |    and    |    and    |    and     |\n",
      "| historians | historian | historian |    hist   | historians |\n",
      "|   alike    |    alik   |    alik   |    alik   |   alike    |\n",
      "|     .      |     .     |     .     |     .     |     .      |\n",
      "+------------+-----------+-----------+-----------+------------+\n",
      "\n",
      "Sentence: An ethereal mist hung over the tranquil lake, creating a mystical atmosphere.\n",
      "\n",
      "+------------+-----------+-----------+-----------+------------+\n",
      "|    Word    |   Porter  |  Snowball | Lancaster | Lemmatizer |\n",
      "+------------+-----------+-----------+-----------+------------+\n",
      "|     An     |     an    |     an    |     an    |     An     |\n",
      "|  ethereal  |   ether   |   ether   |    eth    |  ethereal  |\n",
      "|    mist    |    mist   |    mist   |    mist   |    mist    |\n",
      "|    hung    |    hung   |    hung   |    hung   |    hang    |\n",
      "|    over    |    over   |    over   |     ov    |    over    |\n",
      "|    the     |    the    |    the    |    the    |    the     |\n",
      "|  tranquil  |  tranquil |  tranquil |  tranquil |  tranquil  |\n",
      "|    lake    |    lake   |    lake   |    lak    |    lake    |\n",
      "|     ,      |     ,     |     ,     |     ,     |     ,      |\n",
      "|  creating  |   creat   |   creat   |    cre    |   create   |\n",
      "|     a      |     a     |     a     |     a     |     a      |\n",
      "|  mystical  |   mystic  |   mystic  |    myst   |  mystical  |\n",
      "| atmosphere | atmospher | atmospher |  atmosph  | atmosphere |\n",
      "|     .      |     .     |     .     |     .     |     .      |\n",
      "+------------+-----------+-----------+-----------+------------+\n",
      "\n",
      "Sentence: The voracious reader devoured books from various genres, expanding their knowledge.\n",
      "\n",
      "+-----------+----------+----------+-----------+------------+\n",
      "|    Word   |  Porter  | Snowball | Lancaster | Lemmatizer |\n",
      "+-----------+----------+----------+-----------+------------+\n",
      "|    The    |   the    |   the    |    the    |    The     |\n",
      "| voracious |  voraci  |  voraci  |    vor    | voracious  |\n",
      "|   reader  |  reader  |  reader  |    read   |   reader   |\n",
      "|  devoured |  devour  |  devour  |    devo   |   devour   |\n",
      "|   books   |   book   |   book   |    book   |    book    |\n",
      "|    from   |   from   |   from   |    from   |    from    |\n",
      "|  various  |  variou  | various  |    vary   |  various   |\n",
      "|   genres  |   genr   |   genr   |    genr   |   genres   |\n",
      "|     ,     |    ,     |    ,     |     ,     |     ,      |\n",
      "| expanding |  expand  |  expand  |   expand  |   expand   |\n",
      "|   their   |  their   |  their   |   their   |   their    |\n",
      "| knowledge | knowledg | knowledg |  knowledg | knowledge  |\n",
      "|     .     |    .     |    .     |     .     |     .      |\n",
      "+-----------+----------+----------+-----------+------------+\n",
      "\n",
      "Sentence: The resilient tree withstood the force of the storm, standing tall against adversity.\n",
      "+-----------+-----------+-----------+-----------+------------+\n",
      "|    Word   |   Porter  |  Snowball | Lancaster | Lemmatizer |\n",
      "+-----------+-----------+-----------+-----------+------------+\n",
      "|    The    |    the    |    the    |    the    |    The     |\n",
      "| resilient |   resili  |   resili  |    resy   | resilient  |\n",
      "|    tree   |    tree   |    tree   |    tre    |    tree    |\n",
      "| withstood | withstood | withstood | withstood | withstand  |\n",
      "|    the    |    the    |    the    |    the    |    the     |\n",
      "|   force   |    forc   |    forc   |    forc   |   force    |\n",
      "|     of    |     of    |     of    |     of    |     of     |\n",
      "|    the    |    the    |    the    |    the    |    the     |\n",
      "|   storm   |   storm   |   storm   |   storm   |   storm    |\n",
      "|     ,     |     ,     |     ,     |     ,     |     ,      |\n",
      "|  standing |   stand   |   stand   |   stand   |   stand    |\n",
      "|    tall   |    tall   |    tall   |    tal    |    tall    |\n",
      "|  against  |  against  |  against  |  against  |  against   |\n",
      "| adversity |   advers  |   advers  |   advers  | adversity  |\n",
      "|     .     |     .     |     .     |     .     |     .      |\n",
      "+-----------+-----------+-----------+-----------+------------+\n"
     ]
    }
   ],
   "source": [
    "# Stem each word in the sentences\n",
    "stemmed_sentences = []\n",
    "for sentence in tokenized_sentences:\n",
    "    porter_stemmed = [porter_stemmer.stem(word) for word in sentence]\n",
    "    snowball_stemmed = [snowball_stemmer.stem(word) for word in sentence]\n",
    "    lancaster_stemmed = [lancaster_stemmer.stem(word) for word in sentence]\n",
    "    stemmed_sentences.append(\n",
    "        {\n",
    "            \"Porter\": porter_stemmed,\n",
    "            \"Snowball\": snowball_stemmed,\n",
    "            \"Lancaster\": lancaster_stemmed,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Lemmatize each word in the sentences\n",
    "lemmatized_sentences = []\n",
    "for sentence in tokenized_sentences:\n",
    "    lemmatized = [lemmatizer.lemmatize(word, wordnet.VERB) for word in sentence]\n",
    "    lemmatized_sentences.append(lemmatized)\n",
    "    \n",
    "# Print the results\n",
    "comparetable = PrettyTable()\n",
    "for i, sentence in enumerate(tokenized_sentences):\n",
    "    print(\"\\nSentence:\", sentences[i])\n",
    "    comparetable.field_names = [\"Word\", \"Porter\", \"Snowball\", \"Lancaster\", \"Lemmatizer\"]\n",
    "    for j, word in enumerate(sentence):\n",
    "        comparetable.add_row([word, stemmed_sentences[i][\"Porter\"][j], stemmed_sentences[i][\"Snowball\"][j], stemmed_sentences[i][\"Lancaster\"][j], lemmatized_sentences[i][j]])\n",
    "    print(comparetable)\n",
    "    comparetable.clear_rows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Curiosity Questions\n",
    "<p style=\"font-weight:500;\">Q1. What is paradigm class? Give example.</p>\n",
    "Ans: In linguistics, a paradigm class refers to a set of words or forms that share a similar grammatical pattern or inflectional morphology. It involves grouping words based on their shared grammatical features, such as tense, number, gender, or case. Paradigm classes help linguists analyze and understand the systematic relationships between different forms of words within a language.  \n",
    "\n",
    "Example:  \n",
    "Consider the English verb \"to be\" in the present tense for different pronouns:  \n",
    "\n",
    "I am  \n",
    "You are  \n",
    "We are  \n",
    "He/She/It is\n",
    "\n",
    "In this case, the paradigm class is formed by the variations of the verb \"to be\" based on different pronouns, and they share the same grammatical pattern within the present tense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:500;\">Q2. What are the different types of morphemes. Give example of each.</p>\n",
    "Ans: Morphemes are the smallest units of meaning in a language. There are two main types of morphemes: free morphemes and bound morphemes.  \n",
    "\n",
    "<p style=\"font-weight:500;\">a. Free Morpheme:</p> \n",
    "A free morpheme is a morpheme that can stand alone as a word and carry meaning by itself.\n",
    "\n",
    "Example:  \n",
    "\"Dog\" - In this case, \"dog\" is a free morpheme as it can stand alone and has a distinct meaning.  \n",
    "\n",
    "<p style=\"font-weight:500;\">b. Bound Morpheme:</p>\n",
    "A bound morpheme is a morpheme that cannot stand alone as a word and needs to be attached to a free morpheme to convey meaning.  \n",
    "\n",
    "Example:  \n",
    "\"Un-\" (prefix meaning \"not\") - In the word \"unhappy,\" \"un-\" is a bound morpheme because it cannot stand alone and needs to be attached to \"happy\" to convey the meaning of \"not happy.\"  \n",
    "\n",
    "<p style=\"font-weight:500;\">c. Inflectional Morpheme:</p>\n",
    "An inflectional morpheme is a type of bound morpheme that indicates grammatical information, such as tense, number, or gender.  \n",
    "\n",
    "Example:  \n",
    "\"-s\" (plural marker) in \"cats\" - The morpheme \"-s\" is inflectional as it changes the number of the noun \"cat\" from singular to plural.  \n",
    "\n",
    "<p style=\"font-weight:500;\">d. Derivational Morpheme:</p> \n",
    "A derivational morpheme is a type of bound morpheme that creates a new word or changes the meaning or grammatical category of a word.  \n",
    "\n",
    "Example:  \n",
    "\"-er\" (suffix forming agent nouns) in \"teacher\" - The morpheme \"-er\" is derivational as it changes the base word \"teach\" into a new word with a different grammatical category and meaning.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusion\n",
    "In this experiment we learned about the different types of morphemes and how to generate word forms from root and suffix information using Add-Delete table. We also learned about the comparative study of Porter/Snowball/Lancaster Stemmer and Stemmer vs Lemmatizer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
