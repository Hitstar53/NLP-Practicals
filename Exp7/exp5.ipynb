{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style type=\"text/css\">\n",
    ".tf  {border-collapse:collapse;border-spacing:0;width:100%}\n",
    ".tf td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tf th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tf .tg-0pky{border-color:inherit;text-align:left;vertical-align:top}\n",
    ".col1 { width: 20%;}\n",
    ".col2 { width: 80%;}\n",
    "</style>\n",
    "<table class=\"tf\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky col1\">Name</th>\n",
    "    <th class=\"tg-0pky col2\">Hatim Sawai</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky col1\">UID No.</td>\n",
    "    <td class=\"tg-0pky col2\">2021300108</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td class=\"tg-0pky col1\">Experiment No.</td>\n",
    "    <td class=\"tg-0pky col2\">7</td>\n",
    "  </tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <p style=\"text-align:center;font-weight:500;\">Experiment 7</p>\n",
    "<style type=\"text/css\">\n",
    ".tg  {border-collapse:collapse;border-spacing:0;width:100%}\n",
    ".tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  overflow:hidden;padding:10px 5px;word-break:normal;}\n",
    ".tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;\n",
    "  font-weight:normal;overflow:hidden;padding:10px 10px;word-break:normal;}\n",
    ".tg .tg-0pky{border-color:inherit;text-align:left;vertical-align:top;}\n",
    ".col1 { width: 20%;}\n",
    ".col2 { width: 80%;}\n",
    "</style>\n",
    "<table class=\"tg\">\n",
    "<thead>\n",
    "  <tr>\n",
    "    <th class=\"tg-0pky col1\">Aim</th>\n",
    "    <th class=\"tg-0pky col2\">Perform chunking by analyzing the importance of selecting proper features for training a model and size of training.</th>\n",
    "  </tr>\n",
    "</thead>\n",
    "</table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Installation of NLTK and downloading the required corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import warnings\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.chunk import RegexpParser\n",
    "from prettytable import PrettyTable\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Loading the corpus and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 47959 sentences in the dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Word  POS\n",
       "0      Thousands  NNS\n",
       "1             of   IN\n",
       "2  demonstrators  NNS\n",
       "3           have  VBP\n",
       "4        marched  VBN"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load csv\n",
    "df = pd.read_csv('../dataset/exp5.csv', encoding='isO-8859-1')\n",
    "df1 = df[df['Sentence #'].notna()]\n",
    "print(\"There are\",df1['Sentence #'].iloc[-1].split()[-1],\"sentences in the dataset\")\n",
    "df.drop(['Sentence #', 'Tag'], axis=1, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # remove punctuation\n",
    "    text = text.replace(\"\\n\", \" \") # remove \\n\n",
    "    text = re.sub(r'\\W', ' ', text)  # Remove non-word characters\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespaces\n",
    "    text = re.sub(r'\\d', '', text)  # Remove digits\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "phrase_mapping = {\n",
    "    'NP: {<DT>?<JJ>*<NN>}': 'noun phrase',\n",
    "    'PP: {<IN><NP>}': 'prepositional phrase',\n",
    "    'VP: {<VB.*><NP|PP|CLAUSE>+$}': 'verb phrase'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text corpus (you can replace this with your own text corpus)\n",
    "text_corpus = \"\"\"\n",
    "The quick brown fox jumps over the lazy dog. \n",
    "John likes eating pizza with his friends on Fridays.\n",
    "She sings beautifully in the choir.\n",
    "\"\"\"\n",
    "\n",
    "sentences = sent_tokenize(text_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform chunking using regular expressions\n",
    "def chunk_with_regex(sentence):\n",
    "    grammar = r\"\"\"\n",
    "        NP: {<DT>?<JJ>*<NN>}   # Chunk sequences of DT, JJ, NN\n",
    "        PP: {<IN><NP>}         # Chunk prepositions followed by NP\n",
    "        VP: {<VB.*><NP|PP>*}   # Chunk verbs followed by NP or PP\n",
    "        ADJP: {<JJ>+}          # Chunk sequences of JJ\n",
    "        ADVP: {<RB.*>}         # Chunk adverbs\n",
    "    \"\"\"\n",
    "    parser = RegexpParser(grammar)\n",
    "    parsed_sentence = parser.parse(sentence)\n",
    "    return parsed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform chunking using NLTK library\n",
    "def chunk_with_nltk(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    tagged_words = nltk.pos_tag(words)\n",
    "    grammar = r\"\"\"\n",
    "        NP: {<DT>?<JJ>*<NN>}    # Chunk sequences of DT, JJ, NN\n",
    "        PP: {<IN><NP>}          # Chunk prepositions followed by NP\n",
    "        VP: {<VB.*><NP|PP>*}    # Chunk verbs followed by NP or PP\n",
    "        ADJP: {<JJ>+}           # Chunk sequences of JJ\n",
    "        ADVP: {<RB.*>}          # Chunk adverbs\n",
    "    \"\"\"\n",
    "    parser = nltk.RegexpParser(grammar)\n",
    "    parsed_sentence = parser.parse(tagged_words)\n",
    "    return parsed_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------------+\n",
      "| Tag  |          Phrase         |\n",
      "+------+-------------------------+\n",
      "|  NP  |     The quick brown     |\n",
      "|  NP  |           fox           |\n",
      "|  VP  | jumps over the lazy dog |\n",
      "|  PP  |    over the lazy dog    |\n",
      "|  NP  |       the lazy dog      |\n",
      "|  VP  |          likes          |\n",
      "|  VP  |       eating pizza      |\n",
      "|  NP  |          pizza          |\n",
      "|  VP  |          sings          |\n",
      "| ADVP |       beautifully       |\n",
      "|  PP  |       in the choir      |\n",
      "|  NP  |        the choir        |\n",
      "+------+-------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Perform chunking using regular expressions\n",
    "# Initialize PrettyTable\n",
    "chunk_table = PrettyTable([\"Tag\", \"Phrase\"])\n",
    "for sentence in sentences:\n",
    "    parsed_sentence = chunk_with_regex(nltk.pos_tag(word_tokenize(sentence)))\n",
    "    for subtree in parsed_sentence.subtrees():\n",
    "        if subtree.label() in ['NP', 'PP', 'VP', 'ADJP', 'ADVP']:\n",
    "            chunk_table.add_row([subtree.label(), \" \".join(word for word, tag in subtree.leaves())])\n",
    "\n",
    "# Print the table\n",
    "print(chunk_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Chunking using NLTK library:\n",
      "(S\n",
      "  (NP The/DT quick/JJ brown/NN)\n",
      "  (NP fox/NN)\n",
      "  (VP jumps/VBZ (PP over/IN (NP the/DT lazy/JJ dog/NN)))\n",
      "  ./.)\n",
      "(S\n",
      "  John/NNP\n",
      "  (VP likes/VBZ)\n",
      "  (VP eating/VBG (NP pizza/NN))\n",
      "  with/IN\n",
      "  his/PRP$\n",
      "  friends/NNS\n",
      "  on/IN\n",
      "  Fridays/NNS\n",
      "  ./.)\n",
      "(S\n",
      "  She/PRP\n",
      "  (VP sings/VBZ)\n",
      "  (ADVP beautifully/RB)\n",
      "  (PP in/IN (NP the/DT choir/NN))\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# Perform chunking using NLTK library\n",
    "print(\"\\nChunking using NLTK library:\")\n",
    "for sentence in sentences:\n",
    "    parsed_sentence = chunk_with_nltk(sentence)\n",
    "    print(parsed_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Calculating Emission & Transition Probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Predicting POS tags for a given sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Curiosity Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:500;\">Q1. List a few ways for tagging parts of speech?</p>\n",
    "Ans: There are several ways to tag parts of speech. Some of them are:\n",
    "- Rule-based tagging  \n",
    "<br>\n",
    "- Stochastic tagging  \n",
    "<br>\n",
    "- Transformation-based tagging\n",
    "<br>\n",
    "- Hidden Markov Models\n",
    "<br>\n",
    "- Maximum Entropy Models\n",
    "<br>\n",
    "- Deep Learning Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:500;\">Q2. How do you find the most probable sequence of POS tags from a sequence of text?</p>\n",
    "Ans: The most probable sequence of POS tags from a sequence of text can be found using Hidden Markov Models. The Viterbi algorithm is used to find the most probable sequence of POS tags from a sequence of text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:500;\">Q3. Differentiate between Markov chain and Markov model?</p>\n",
    "Ans: Markov chain is a stochastic model describing a sequence of possible events in which the probability of each event depends only on the state attained in the previous event. Markov model is a model that assumes that the future state depends only on the current state and not on the sequence of events that preceded it. Markov chain is a special case of Markov model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:500;\">Q4. How you can identify whether a system follows a Markov Process?</p>\n",
    "Ans: A system follows a Markov Process if it satisfies the Markov property. The Markov property states that the future state of the system depends only on the current state and not on the sequence of events that preceded it. If the system satisfies the Markov property, then it follows a Markov Process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"font-weight:500;\">Q5.  Explain the use of Markov Chains in text generation algorithms.</p>\n",
    "Ans: Markov Chains are used in text generation algorithms to generate text that is similar to the input text. Markov Chains are used to model the probability of the next word in a sequence of words given the current word. This probability is used to generate the next word in the sequence. Markov Chains are used to generate text that is similar to the input text by sampling the next word from the probability distribution of the next word given the current word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Conclusion\n",
    "In this experiment we learned about Hidden Markov Models and how to implement a Hidden Markov Model for tagging Parts of Speech. We also learned how to calculate the emission and transition matrix for tagging Parts of Speech using Hidden Markov Model. We also learned how to find the POS tag of a given sentence using Hidden Markov Model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
